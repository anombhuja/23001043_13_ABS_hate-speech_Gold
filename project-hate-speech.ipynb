{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "accf8097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [30/Nov/2023 21:14:27] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/Nov/2023 21:14:27] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [30/Nov/2023 21:14:29] \"GET /docs/ HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/Nov/2023 21:14:29] \"GET /flasgger_static/swagger-ui.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [30/Nov/2023 21:14:29] \"GET /flasgger_static/swagger-ui-bundle.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [30/Nov/2023 21:14:29] \"GET /flasgger_static/lib/jquery.min.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [30/Nov/2023 21:14:29] \"GET /flasgger_static/swagger-ui-standalone-preset.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [30/Nov/2023 21:14:30] \"GET /docs.json HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/Nov/2023 21:15:00] \"POST /text-processing-file HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import logging\n",
    "import pandas as pd\n",
    "from flask import Flask, jsonify, request\n",
    "from flasgger import Swagger, LazyJSONEncoder, swag_from\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Membaca file csv daftar kata baku dan tidak baku\n",
    "df_kamusalay = pd.read_csv('C:/Users/ROG/Documents/Data-20231031T003049Z-001/project-hate-speech/Asset Challenge/new_kamusalay.csv', encoding='latin-1', header=None)\n",
    "df_kamusalay.columns = [\"tidak_baku\", \"baku\"]\n",
    "kamus_alay = dict(zip(df_kamusalay[\"tidak_baku\"], df_kamusalay[\"baku\"]))\n",
    "\n",
    "# Membaca file csv kata kasar\n",
    "df_abusive = pd.read_csv('C:/Users/ROG/Documents/Data-20231031T003049Z-001/project-hate-speech/Asset Challenge/abusive.csv')\n",
    "\n",
    "# Mengambil daftar kata kasar\n",
    "kata_abusive = df_abusive['ABUSIVE'].tolist()\n",
    "\n",
    "app.json_encoder = LazyJSONEncoder\n",
    "swagger_template = {\n",
    "    \"info\": {\n",
    "        \"title\": \"API Documentation for Data Processing and Modeling\",\n",
    "        \"version\": \"1.0.0\",\n",
    "        \"description\": \"Dokumentasi API untuk Data Processing dan Modeling\",\n",
    "    },\n",
    "    \"host\": \"127.0.0.1:5000\"\n",
    "}\n",
    "\n",
    "swagger_config = {\n",
    "    \"headers\": [],\n",
    "    \"specs\": [\n",
    "        {\n",
    "            \"endpoint\": 'docs',\n",
    "            \"route\": '/docs.json',\n",
    "        }\n",
    "    ],\n",
    "    \"static_url_path\": \"/flasgger_static\",\n",
    "    \"swagger_ui\": True,\n",
    "    \"specs_route\": \"/docs/\"\n",
    "}\n",
    "\n",
    "swagger = Swagger(app, template=swagger_template, config=swagger_config)\n",
    "\n",
    "@swag_from('C:/Users/ROG/Documents/Data-20231031T003049Z-001/project-hate-speech/docs/hello_world.yml', methods=['GET'])\n",
    "@app.route('/', methods=['GET'])\n",
    "def hello_world():\n",
    "    json_response = {\n",
    "        'status_code': 200,\n",
    "        'description': \"Menyapa Hello World\",\n",
    "        'data': \"Hello World\",\n",
    "    }\n",
    "    return jsonify(json_response)\n",
    "\n",
    "@swag_from('C:/Users/ROG/Documents/Data-20231031T003049Z-001/project-hate-speech/docs/text.yml', methods=['GET'])\n",
    "@app.route('/text', methods=['GET'])\n",
    "def text():\n",
    "    json_response = {\n",
    "        'status_code': 200,\n",
    "        'description': \"Original Teks\",\n",
    "        'data': \"Text\",\n",
    "    }\n",
    "    return jsonify(json_response)\n",
    "\n",
    "@swag_from('C:/Users/ROG/Documents/Data-20231031T003049Z-001/project-hate-speech/docs/text_clean.yml', methods=['GET'])\n",
    "@app.route('/text_clean', methods=['GET'])\n",
    "def text_clean():\n",
    "    json_response = {\n",
    "        'status_code': 200,\n",
    "        'description': \"Teks yang sudah dibersihkan\",\n",
    "        'data': \"Text Clean\",\n",
    "    }\n",
    "    return jsonify(json_response)\n",
    "\n",
    "@swag_from('C:/Users/ROG/Documents/Data-20231031T003049Z-001/project-hate-speech/docs/text_processing.yml', methods=['POST'])\n",
    "@app.route('/text_processing', methods=['POST'])\n",
    "def text_processing():\n",
    "    text = request.form.get('text')\n",
    "    json_response = {\n",
    "        'status_code': 200,\n",
    "        'description': \"Teks yang sudah diproses\",\n",
    "        'data': re.sub(r'[^a-zA-Z0-9]', ' ', text)\n",
    "    }\n",
    "    return jsonify(json_response)\n",
    "\n",
    "\n",
    "@swag_from(\"C:/Users/ROG/Documents/Data-20231031T003049Z-001/project-hate-speech/docs/text_processing_file.yml\", methods=['POST'])\n",
    "@app.route('/text-processing-file', methods=['POST'])\n",
    "def text_processing_file():\n",
    "    global post_df\n",
    "\n",
    "    # Menggunakan request.files['file'] untuk mendapatkan file yang diunggah\n",
    "    file = request.files['file']\n",
    "\n",
    "    # IMPORT FILE OBJECT INTO PANDAS DATAFRAME (Anda bisa menyertakan nrows jika perlu)\n",
    "    post_df = pd.read_csv(file, encoding='latin-1')\n",
    "\n",
    "    # Menjaga DataFrame, tidak mengubahnya menjadi Series\n",
    "    post_df = post_df[['Tweet']]\n",
    "\n",
    "    # DROP DUPLICATED TWEETS\n",
    "    post_df.drop_duplicates(inplace=True)\n",
    "\n",
    "    # CREATE NEW NUMBER OF CHARACTERS (NO_CHAR) COLUMN THAT CONSISTS OF LENGTH OF TWEET CHARACTERS\n",
    "    post_df['no_char'] = post_df['Tweet'].apply(len)\n",
    "\n",
    "    # CREATE NEW NUMBER OF WORDS (NO_WORDS) COLUMN THAT CONSISTS OF NUMBER OF WORDS OF EACH TWEET\n",
    "    post_df['no_words'] = post_df['Tweet'].apply(lambda x: len(x.split()))\n",
    "\n",
    "#   CREATE A FUNCTION TO CLEAN DATA FROM ANY NON ALPHA-NUMERIC (AND NON-SPACE) CHARACTERS, AND STRIP IT FROM LEADING/TRAILING SPACES\n",
    "    def tweet_cleansing(x):\n",
    "        tweet = x\n",
    "        word_tweet = tweet.split()\n",
    "        cleaned_tweet = re.sub(r'\\\\x[a-f0-9]{2}', '', ' '.join(word_tweet))\n",
    "        # untuk membersihkan non alphanumeric\n",
    "        cleaned_tweet = re.sub(r'[^a-zA-Z0-9 ]', '', cleaned_tweet).lower()\n",
    "        kata_bersih = [kamus_alay.get(word, word) for word in cleaned_tweet.split()]\n",
    "        kata_bersih = [word for word in kata_bersih if word not in kata_abusive]\n",
    "        return ' '.join(kata_bersih)\n",
    "\n",
    "    result = {\n",
    "        'status_code': 200,\n",
    "        'message': 'Successful response',\n",
    "        'data': {\n",
    "            'no_char': post_df['no_char'].tolist(),\n",
    "            'no_words': post_df['no_words'].tolist(),\n",
    "            'cleaned_tweets': post_df['Tweet'].apply(tweet_cleansing).tolist()\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return jsonify(result)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b745d4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
